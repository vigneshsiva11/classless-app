<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenAI Whisper Transcription Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            text-align: center;
            margin-bottom: 30px;
        }
        .status {
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
            font-weight: bold;
        }
        .status.ready { background-color: #d4edda; color: #155724; }
        .status.recording { background-color: #fff3cd; color: #856404; }
        .status.processing { background-color: #cce5ff; color: #004085; }
        .status.success { background-color: #d1ecf1; color: #0c5460; }
        .status.error { background-color: #f8d7da; color: #721c24; }
        
        .controls {
            display: flex;
            gap: 10px;
            margin: 20px 0;
            justify-content: center;
        }
        
        button {
            padding: 12px 24px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
            font-weight: bold;
            transition: background-color 0.3s;
        }
        
        .record-btn {
            background-color: #dc3545;
            color: white;
        }
        .record-btn:hover { background-color: #c82333; }
        .record-btn.recording { background-color: #28a745; }
        .record-btn.recording:hover { background-color: #218838; }
        
        .transcribe-btn {
            background-color: #007bff;
            color: white;
        }
        .transcribe-btn:hover { background-color: #0056b3; }
        .transcribe-btn:disabled { background-color: #6c757d; cursor: not-allowed; }
        
        .clear-btn {
            background-color: #6c757d;
            color: white;
        }
        .clear-btn:hover { background-color: #545b62; }
        
        .audio-player {
            margin: 20px 0;
            text-align: center;
        }
        
        .transcription-result {
            background-color: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 5px;
            padding: 20px;
            margin: 20px 0;
            display: none;
        }
        
        .transcription-text {
            font-size: 18px;
            line-height: 1.6;
            margin-bottom: 15px;
        }
        
        .transcription-info {
            font-size: 14px;
            color: #6c757d;
        }
        
        .log {
            background-color: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 5px;
            padding: 15px;
            margin: 20px 0;
            max-height: 200px;
            overflow-y: auto;
            font-family: monospace;
            font-size: 12px;
        }
        
        .language-selector {
            margin: 20px 0;
            text-align: center;
        }
        
        select {
            padding: 8px 12px;
            border: 1px solid #ced4da;
            border-radius: 4px;
            font-size: 16px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ OpenAI Whisper Transcription Test</h1>
        
        <div class="status" id="status">Ready to record</div>
        
        <div class="language-selector">
            <label for="language">Language:</label>
            <select id="language">
                <option value="en-US">English (US)</option>
                <option value="hi-IN">Hindi</option>
                <option value="ta-IN">Tamil</option>
                <option value="bn-IN">Bengali</option>
                <option value="te-IN">Telugu</option>
                <option value="mr-IN">Marathi</option>
                <option value="gu-IN">Gujarati</option>
                <option value="pa-IN">Punjabi</option>
            </select>
        </div>
        
        <div class="controls">
            <button id="recordBtn" class="record-btn">üé§ Start Recording</button>
            <button id="transcribeBtn" class="transcribe-btn" disabled>üìù Transcribe</button>
            <button id="clearBtn" class="clear-btn">üóëÔ∏è Clear</button>
        </div>
        
        <div class="audio-player" id="audioPlayer" style="display: none;">
            <audio id="audioElement" controls></audio>
        </div>
        
        <div class="transcription-result" id="transcriptionResult">
            <div class="transcription-text" id="transcriptionText"></div>
            <div class="transcription-info" id="transcriptionInfo"></div>
        </div>
        
        <div class="log" id="log">
            <div>Log will appear here...</div>
        </div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let audioBlob = null;
        
        const recordBtn = document.getElementById('recordBtn');
        const transcribeBtn = document.getElementById('transcribeBtn');
        const clearBtn = document.getElementById('clearBtn');
        const status = document.getElementById('status');
        const audioPlayer = document.getElementById('audioPlayer');
        const audioElement = document.getElementById('audioElement');
        const transcriptionResult = document.getElementById('transcriptionResult');
        const transcriptionText = document.getElementById('transcriptionText');
        const transcriptionInfo = document.getElementById('transcriptionInfo');
        const log = document.getElementById('log');
        const languageSelect = document.getElementById('language');
        
        function updateStatus(message, type) {
            status.textContent = message;
            status.className = `status ${type}`;
            logMessage(`${type.toUpperCase()}: ${message}`);
        }
        
        function logMessage(message) {
            const timestamp = new Date().toLocaleTimeString();
            const logEntry = document.createElement('div');
            logEntry.textContent = `[${timestamp}] ${message}`;
            log.appendChild(logEntry);
            log.scrollTop = log.scrollHeight;
        }
        
        function clearLog() {
            log.innerHTML = '<div>Log cleared...</div>';
        }
        
        async function startRecording() {
            try {
                updateStatus('Requesting microphone access...', 'processing');
                
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };
                
                mediaRecorder.onstop = () => {
                    audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    const audioUrl = URL.createObjectURL(audioBlob);
                    audioElement.src = audioUrl;
                    audioPlayer.style.display = 'block';
                    
                    updateStatus(`Recording completed! Size: ${(audioBlob.size / 1024).toFixed(1)} KB`, 'success');
                    transcribeBtn.disabled = false;
                    recordBtn.textContent = 'üé§ Start Recording';
                    recordBtn.classList.remove('recording');
                };
                
                mediaRecorder.start();
                recordBtn.textContent = '‚èπÔ∏è Stop Recording';
                recordBtn.classList.add('recording');
                updateStatus('Recording... Click "Stop Recording" when done', 'recording');
                
                logMessage('Recording started');
                
            } catch (error) {
                console.error('Error starting recording:', error);
                updateStatus(`Recording failed: ${error.message}`, 'error');
            }
        }
        
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
            }
        }
        
        async function transcribeAudio() {
            if (!audioBlob) {
                updateStatus('No audio to transcribe', 'error');
                return;
            }
            
            try {
                updateStatus('Transcribing audio with OpenAI Whisper...', 'processing');
                transcribeBtn.disabled = true;
                
                const formData = new FormData();
                const timestamp = Date.now();
                const uniqueFilename = `recording_${timestamp}.wav`;
                formData.append('audio', audioBlob, uniqueFilename);
                formData.append('language', languageSelect.value);
                formData.append('timestamp', timestamp.toString());
                
                logMessage(`Sending request with filename: ${uniqueFilename}, language: ${languageSelect.value}`);
                
                const response = await fetch('/api/transcribe', {
                    method: 'POST',
                    body: formData
                });
                
                logMessage(`Response status: ${response.status}`);
                
                const result = await response.json();
                logMessage(`Response: ${JSON.stringify(result, null, 2)}`);
                
                if (result.success) {
                    transcriptionText.textContent = result.data.text;
                    transcriptionInfo.textContent = `Words: ${result.data.words}, Confidence: ${Math.round(result.data.confidence * 100)}%, Source: ${result.data.source}, Language: ${result.data.language}`;
                    transcriptionResult.style.display = 'block';
                    
                    const sourceMessage = result.data.source === 'openai-whisper' ? ' using OpenAI Whisper' : 
                                        result.data.source === 'gemini-ai' ? ' using Gemini AI' : ' using mock transcription';
                    
                    updateStatus(`Transcription completed successfully${sourceMessage}!`, 'success');
                } else {
                    updateStatus(`Transcription failed: ${result.error}`, 'error');
                }
                
            } catch (error) {
                console.error('Error transcribing audio:', error);
                updateStatus(`Failed to transcribe audio: ${error.message}`, 'error');
            } finally {
                transcribeBtn.disabled = false;
            }
        }
        
        function clearRecording() {
            audioBlob = null;
            audioPlayer.style.display = 'none';
            transcriptionResult.style.display = 'none';
            transcribeBtn.disabled = true;
            recordBtn.textContent = 'üé§ Start Recording';
            recordBtn.classList.remove('recording');
            updateStatus('Ready to record', 'ready');
            clearLog();
        }
        
        // Event listeners
        recordBtn.addEventListener('click', () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                stopRecording();
            } else {
                startRecording();
            }
        });
        
        transcribeBtn.addEventListener('click', transcribeAudio);
        clearBtn.addEventListener('click', clearRecording);
        
        // Initialize
        updateStatus('Ready to record', 'ready');
        logMessage('OpenAI Whisper transcription test initialized');
        logMessage('Make sure you have OPENAI_API_KEY set in your .env.local file for real transcription');
    </script>
</body>
</html>
